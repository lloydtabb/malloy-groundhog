>>>markdown
Welcome to the Groundhog Day data analysis demo in Malloy!

The purpose of this demo is to:

1. Help me learn Malloy (I'm a complete newb)

2. Highlight current sharp edges and areas of improvement for the Malloy team
   from the perspective of said newb.

3. Better understand the prophetic powers of prognosticating groundhogs through
   the power of data.

## Assumptions
To make things simple we will define "Spring" as:

\> The maximum "daily average maximum temperature" of Feb and March is >= 40

I can't say for certain this is how the groundhogs themselves define "spring",
but it's good enough for our purpose. Future iterations should probably
refine this metric to each state and preferably interview the groundhogs
themselves.

## Data
Data is included in this repository in both the raw and generated form. To
re-generate the data from it's `raw/` form into it's `gen/` form run:

```
make gen
```

Raw data used in this demo can be downloaded from

* `raw_data/noaa.txt`: ncei.noaa.gov
  (`https://www.ncei.noaa.gov/pub/data/cirs/climdiv/climdiv-norm-tmaxdv-v1.0.0-{date}`
  (note: the date changes)
  * This is a narly custom text format. See
    [`scripts/noaa.py`](./scripts/noaa.py) for how I converted the data to CSV
* `raw_data/groundhogs.json` copy/pasted from https://groundhog-day.com/api

The csv files are generated using the python scripts in `scripts/`

## Getting our Groundhogs
In Malloy we use a `source` to pull data in and then `extend` it to `rename`
and calculate (`dimension`) a few fields, as well as define a primary key
for joins.
>>>malloy
source: GroundhogsRaw is duckdb.table("./gen/groundhogs.csv") extend {
  primary_key: year_
  rename: id is slug, state is region
  -- null for fields like: "No Record.,1897-02-02"
  where: shadow != null
  dimension:
    year_ is year(early_spring),
    predict_early_spring is shadow = 0
}
>>>markdown
The next bit I would _like_ to do in a single pipeline like the following,
but I have to do it in multiple named steps instead:

```
source: ... extend { ... } -> { project: ... } -> { primary_key: }
```

(this is for the malloy devs) the things blocking this are:

1. Get only a certain set of fields for better viewing. Unforunately in the
   `extend` you have to `accept` all fields you use in a `dimension` meaning I
   need the intermediary `project` to fully filter them (I like my data to be
   neat when I print)

2. You don't seem to be able to do a pipeline of `source -> query -> source`,
   instead you need to name each intermediary stage.

3. You cannot define a primary key in a query (only a source)

Anyway, let's work around these issues and transform our data so that its
dimensions are better aligned with the kinds of questions we might ask it:

* year_state will be the primary key we join against our temperature data.

* `id` is the "unique name" of the groundhog that we will group by.

* `saw_shadow` indicates whether the groundhog predicts spring will "come late"
  (be at least 6 weeks away)

>>>malloy
query: G1 is GroundhogsRaw -> {
   project:
    year_ is year(early_spring),
    state,
    year_state is concat(year_, ' ', state),
    predict_early_spring,
    name, id
}
source: Groundhogs is G1 extend {
  -- you can't do `primary_key: (year_, state)`
  primary_key: year_state
}
>>>markdown
Before we continue, take a look at the current schema.

>>>malloy
run: Groundhogs -> {
  project: *
  top: 10
}

>>>markdown
## Get our Temperature data

Now that we have our groundhogs and their predictions, let's get some data to
join against them. As noted in [Data]{#data} we are using data from
[ncei.noaa.gov](ncei.noaa.gov) transformed to CSV with a script.

\> Note: temp_max is the **average maximum temperature** across all days in the
\> month (it is not the maximum maximum temperature)

The below query needs to be split into three parts because:
1. Malloy doesn't support "projecting" a value that was aggregated
   in that `extend` block
   (I can't do `is_early_spring is early_spring_temp_max >= 40`)
2. query doesn't support primary_key
>>>malloy

source: T1 is duckdb.table('./gen/TempMax.csv') extend {
  accept:      `date`, state, max_temp
  rename:      temp_max is max_temp
}
query: T2 is T1 -> {
  where:     month(`date`) ? 2 to 3
  aggregate: early_spring_temp_max is max(temp_max)
  group_by:
    year_ is year(`date`),
    state
} -> {
  project:
    *,
    year_state is concat(year_, ' ', state)
    is_early_spring is early_spring_temp_max >= 40
}

source: YearStateSpring is T2 extend {
  primary_key: year_state
}
>>>markdown
## Sidequest: get context

It would be nice to include some contextual information such as how often is a
given state has early spring. It would also be nice to have some kind of
reference for how difficult it is for a prophet (groundhog or not) to predict
whether spring will come for a given place. Let's use an extremely simplistic
measurement as the distance (absolute difference) from our definition of spring.
We'll also compute the maximum distance so we have something to normalize with.

Let's create some sources for that.

>>>malloy

query: PES0 is YearStateSpring -> {
  group_by: state
  aggregate:
    ratio_early_spring is sum(pick 1 when is_early_spring else 0) / count()
    state_avg_distance_spring is sum(abs(40 - early_spring_temp_max)) / count()
    -- maximum distance across all states/years
    max_distance_spring is all(max(abs(40 - early_spring_temp_max)))
} -> {
  project:
    -- The distance factor lets us put a weight on the prophetic
    -- vision of our shadow viewing groundpig.
    *, state_distance_factor is state_avg_distance_spring / max_distance_spring
}
source: AllYearsStateSpring is PES0 extend {
  primary_key: state
}

>>>markdown
## Putting it all together
Now that we have our data let's join it and perform the calculations we care
about

>>>malloy
query: GroundhogPredictions is Groundhogs -> {
  join_one: YearStateSpring with year_state
  join_one: AllYearsStateSpring with state
  project:
    *,
    YearStateSpring.is_early_spring,
    AllYearsStateSpring.state_avg_distance_spring,
    AllYearsStateSpring.state_distance_factor,
    accurate is YearStateSpring.is_early_spring = predict_early_spring,
    state_ratio_early_spring is AllYearsStateSpring.ratio_early_spring,

}

>>>markdown
Finally let's aggregate our primary result (`ratio_accuracy`, the most important
metric for any prophetic rodent) as well as some reference points such as
`ratio_predict_early_spring` and `ratio_is_early_spring`.

Let's also get often the groundhog predicts spring to compare against accuracy
and state averages.

>>>malloy
query: GroundhogAccuracy is GroundhogPredictions -> {
  group_by:
    id, name, state
    -- note: remains constant
    state_ratio_early_spring, state_distance_factor, state_avg_distance_spring
  aggregate:
    ratio_accuracy is avg(pick 1 when accurate else 0),
    ratio_predict_early_spring is
      sum(pick 1 when predict_early_spring else 0) / count()
    ratio_is_early_spring is
      sum(pick 1 when is_early_spring else 0) / count()
    num_predictions is count(),
    earliest_prediction is min(concat(year_)),
}

query: RodentProphets is GroundhogAccuracy -> {
  project:
    name,

    # percent
    ratio_accuracy,

    -- multiply by a thousand to make it seem more significant
    absolute_prophetic_wisdom is 1000 * ratio_accuracy / state_distance_factor
    state_avg_distance_spring,

    # percent
    ratio_is_early_spring,

    # percent
    state_ratio_early_spring,

    # percent
    ratio_predict_early_spring,

    state,
    earliest_prediction,
    num_predictions,
}

-- Order and display data to draw (false) conclusions
run: RodentProphets -> {
  project: *
  order_by:
    ratio_accuracy desc, ratio_is_early_spring desc
  where:
    num_predictions > 5
}
>>>markdown

Right away we can see that the top groundhog "General Beauregard Lee" is a
cheater: sure he's accurate 90% of the time, but it's also spring 100% of the
time in Georgia!

Prophet "Chuckles" is a significantly more interesting case. Not only is he
prophetic, but his state has undergone quite a lot of warming: it's lifetime
average of early spring is only 30%, but it's average since predictions started
(2008) is up to 73%.

There's plenty of rodents we could mock: The next three have only an 71% - 83%
accuracy in a state that has early spring 100% of the time. However, it's
important to remember they might have a different definition of "spring" then
we do.

But wait, let's see how things look if instead of accuracy we sort by the aptly
named `maximum_prophetic_wisdom`

>>>malloy
-- Order and display data to draw prophetic conclusions
run: RodentProphets -> {
  project: *
  order_by:
    absolute_prophetic_wisdom desc
  where:
    num_predictions > 5
}

>>>markdown
We can now see clearly that General Boregard is as untinteresting as he seemed,
with only 1,576 points of prophecy.  Being highly accurate in a state that is
on average 25 degrees above "spring" is not hard.

Chuckles, as we also thought, is very high (top in fact) with 9,689 points of
prophetic wisdom. He began his illustrious career in only 2008 and has
successfully dominated the prophecy charts 15 times. The absolute legend
Punxsutawney Phil himself clocks in at only 5,569, proving that there is
still room for the young in the field of prophecy.

## Obligatory legal warning

I am neither a statistician nor a data scientist (I am, in fact, a programmer
with a love for programming languages including building my own from [absolute
scratch](http://github.com/civboot/fngi)) and these measurements are completely
made up. If you know the _proper_ way to compare groundhog abilities please
open an issue or a PR! If it's not too much work, I will add an adendum :D

This code is Community Commons (CC0), but I strongly recommend against copying
either it or it's methology unless (perhaps) if it's on your own journey to
learning Malloy or you would like to make fun of it.


